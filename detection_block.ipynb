{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uUDueT3m9mVn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pbcquoc/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.slim.nets\n",
    "from tensorflow.contrib.slim.nets import vgg \n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config grid system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MIKQbEdU9mVw"
   },
   "outputs": [],
   "source": [
    "# Size grid system \n",
    "cell_size = 7 \n",
    "# The number of boundary boxes to predict per grid cell\n",
    "box_per_cell = 2\n",
    "# The size of the input image\n",
    "img_size = 224\n",
    "# Labels\n",
    "classes = {'circle':0, 'triangle':1,  'rectangle':2}\n",
    "nclass = len(classes)\n",
    "\n",
    "box_scale = 5.0\n",
    "noobject_scale = 0.5\n",
    "batch_size = 128\n",
    "\n",
    "epochs = 10\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mPSdYB0F9mVz"
   },
   "outputs": [],
   "source": [
    "def load():\n",
    "    labels = json.load(open('train/labels.json'))\n",
    "    N = len(labels)\n",
    "    # matrix contain image\n",
    "    X = np.zeros((N, img_size, img_size, 3), dtype='uint8')\n",
    "    # matrix contain labels corresponding images\n",
    "    y = np.zeros((N,cell_size, cell_size, 5+nclass))\n",
    "    for idx, label in enumerate(labels):\n",
    "        img = cv2.imread(\"train/{}.png\".format(idx))\n",
    "        # normalize [0-1]\n",
    "        X[idx] = img\n",
    "        for box in label['boxes']:\n",
    "            x1, y1 = box['x1'], box['y1']\n",
    "            x2, y2 = box['x2'], box['y2']\n",
    "            # one-hot vector \n",
    "            cl = [0]*len(classes)\n",
    "            cl[classes[box['class']]] = 1\n",
    "            # Center boundary box\n",
    "            x_center, y_center, w, h = (x1+x2)/2.0, (y1+y2)/2.0, x2-x1, y2-y1\n",
    "            # Index object on  7x7 grid matrix\n",
    "            x_idx, y_idx = int(x_center/img_size*cell_size), int(y_center/img_size*cell_size)\n",
    "            # Assign labels matrix \n",
    "            y[idx, y_idx, x_idx] = 1, x_center, y_center, w, h, *cl\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32791,
     "status": "ok",
     "timestamp": 1545695464701,
     "user": {
      "displayName": "Quoc Pham",
      "photoUrl": "https://lh3.googleusercontent.com/-fhmgGol9Tbo/AAAAAAAAAAI/AAAAAAAAAoE/dyUSaTspIFQ/s64/photo.jpg",
      "userId": "10232171753645408525"
     },
     "user_tz": -420
    },
    "id": "MxvjOzQ79mV3",
    "outputId": "265d5936-5f94-4713-e123-fb2d1694b32a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.png\r\n",
      "10000.png\r\n",
      "10001.png\r\n",
      "10002.png\r\n",
      "10003.png\r\n",
      "10004.png\r\n",
      "10005.png\r\n",
      "10006.png\r\n",
      "10007.png\r\n",
      "10008.png\r\n",
      "ls: write error: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "! wget --quiet --no-check-certificate 'https://docs.google.com/uc?export=download&id=12sZLOe5VDvAqGHcjJh7mVmjB6HPeIEJh' -O train.zip\n",
    "! unzip -o -q train.zip\n",
    "! ls train | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UgwY4lon9mV7"
   },
   "outputs": [],
   "source": [
    "X, y = load()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jxklBSPf9mV-"
   },
   "outputs": [],
   "source": [
    "def vgg16(inputs, is_training):\n",
    "    with tf.variable_scope(\"vgg_16\"):\n",
    "        with slim.arg_scope(vgg.vgg_arg_scope()):\n",
    "            net = slim.repeat(inputs, 2, slim.conv2d, 16, [3, 3], scope='conv1')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 32, [3, 3], scope='conv2')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 64, [3, 3], scope='conv3')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv4')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool4')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 256, [3, 3], scope='conv5')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool5')\n",
    "            net = slim.conv2d(net, 512, [1, 1], scope='fc6')   \n",
    "\n",
    "            net = slim.conv2d(net, 13, [1, 1], activation_fn=None, scope='fc7')\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IOU function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mKqBZTTc9mWC"
   },
   "outputs": [],
   "source": [
    "def compute_iou(boxes1, boxes2, scope='iou'):\n",
    "    \"\"\"calculate ious\n",
    "    Args:\n",
    "      boxes1: 5-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4]  ====> (x_center, y_center, w, h)\n",
    "      boxes2: 5-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4] ===> (x_center, y_center, w, h)\n",
    "    Return:\n",
    "      iou: 4-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope):\n",
    "        # transform (x_center, y_center, w, h) to (x1, y1, x2, y2)\n",
    "        boxes1_t = tf.stack([boxes1[..., 0] - boxes1[..., 2] / 2.0,\n",
    "                             boxes1[..., 1] - boxes1[..., 3] / 2.0,\n",
    "                             boxes1[..., 0] + boxes1[..., 2] / 2.0,\n",
    "                             boxes1[..., 1] + boxes1[..., 3] / 2.0],\n",
    "                            axis=-1)\n",
    "\n",
    "        boxes2_t = tf.stack([boxes2[..., 0] - boxes2[..., 2] / 2.0,\n",
    "                             boxes2[..., 1] - boxes2[..., 3] / 2.0,\n",
    "                             boxes2[..., 0] + boxes2[..., 2] / 2.0,\n",
    "                             boxes2[..., 1] + boxes2[..., 3] / 2.0],\n",
    "                            axis=-1)\n",
    "\n",
    "        # calculate the left up point & right down point\n",
    "        lu = tf.maximum(boxes1_t[..., :2], boxes2_t[..., :2])\n",
    "        rd = tf.minimum(boxes1_t[..., 2:], boxes2_t[..., 2:])\n",
    "\n",
    "        # intersection\n",
    "        intersection = tf.maximum(0.0, rd - lu)\n",
    "        inter_square = intersection[..., 0] * intersection[..., 1]\n",
    "\n",
    "        # calculate the boxs1 square and boxs2 square\n",
    "        square1 = boxes1[..., 2] * boxes1[..., 3]\n",
    "        square2 = boxes2[..., 2] * boxes2[..., 3]\n",
    "\n",
    "        union_square = tf.maximum(square1 + square2 - inter_square, 1e-10)\n",
    "\n",
    "    return tf.clip_by_value(inter_square / union_square, 0.0, 1.0)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function - Classfication Loss - Localization Loss - Confidence Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-HEcGXqq9mWF"
   },
   "outputs": [],
   "source": [
    "def loss_layer(predicts, labels, scope='loss_layer'):\n",
    "    \"\"\"calculate loss function\n",
    "    Args:\n",
    "      predicts: 4-D tensor [batch_size, 7, 7, 5*nbox+n_class] \n",
    "      labels: 4-D tensor [batch_size, 7, 7, 5+n_class]\n",
    "    Return:\n",
    "      loss: scalar\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope):\n",
    "        offset = np.transpose(np.reshape(np.array(\n",
    "            [np.arange(cell_size)] * cell_size * box_per_cell),\n",
    "            (box_per_cell, cell_size, cell_size)), (1, 2, 0))\n",
    "        offset = offset[None, :]\n",
    "        offset = tf.constant(offset, dtype=tf.float32)\n",
    "        offset_tran = tf.transpose(offset, (0, 2, 1, 3))\n",
    "        \n",
    "        predict_object = predicts[..., :box_per_cell]\n",
    "        \n",
    "        predict_box_offset = tf.reshape(predicts[...,box_per_cell:5*box_per_cell], (-1, cell_size, cell_size, box_per_cell, 4))\n",
    "        \n",
    "        predict_class = predicts[...,5*box_per_cell:]\n",
    "        \n",
    "        predict_normalized_box = tf.stack(\n",
    "                                    [(predict_box_offset[..., 0] + offset) / cell_size,\n",
    "                                     (predict_box_offset[..., 1] + offset_tran) / cell_size,\n",
    "                                     tf.square(predict_box_offset[..., 2]),\n",
    "                                    tf.square(predict_box_offset[..., 3])], axis=-1)\n",
    "\n",
    "        true_object = labels[..., :1]\n",
    "        true_box = tf.reshape(labels[..., 1:5], (-1, cell_size, cell_size, 1, 4))\n",
    "        \n",
    "        true_normalized_box = tf.tile(true_box, (1, 1, 1, box_per_cell, 1))/img_size\n",
    "        true_class = labels[..., 5:]\n",
    "        \n",
    "        true_box_offset =  tf.stack(\n",
    "                                    [true_normalized_box[..., 0] * cell_size - offset,\n",
    "                                     true_normalized_box[..., 1] * cell_size - offset_tran,\n",
    "                                     tf.sqrt(true_normalized_box[..., 2]),\n",
    "                                     tf.sqrt(true_normalized_box[..., 3])], axis=-1)\n",
    "        \n",
    "        predict_iou = compute_iou(true_normalized_box, predict_normalized_box)\n",
    "        \n",
    "        object_mask = tf.reduce_max(predict_iou, 3, keepdims=True)  \n",
    "        \n",
    "        iou_metric = tf.reduce_mean(tf.reduce_sum(object_mask, axis=[1,2,3])/tf.reduce_sum(true_object, axis=[1,2,3]))\n",
    "        \n",
    "        object_mask = tf.cast((predict_iou>=object_mask), tf.float32)*true_object\n",
    "\n",
    "        noobject_mask = tf.ones_like(object_mask) - object_mask\n",
    "        \n",
    "        ## class loss\n",
    "        class_delta = true_object*(predict_class - true_class)\n",
    "        class_loss = tf.reduce_mean(tf.reduce_sum(tf.square(class_delta), axis=[1,2,3]), name='class_loss')\n",
    "        \n",
    "        ## object loss\n",
    "        object_delta = object_mask*(predict_object - predict_iou)\n",
    "        object_loss = tf.reduce_mean(tf.reduce_sum(tf.square(object_delta), axis=[1,2,3]), name='object_loss')\n",
    "        \n",
    "        ## noobject loss\n",
    "        noobject_delta = noobject_mask*predict_object\n",
    "        noobject_loss = tf.reduce_mean(tf.reduce_sum(tf.square(noobject_delta), axis=[1,2,3]), name='noobject_loss')\n",
    "        \n",
    "        ## coord loss\n",
    "        box_mask = tf.expand_dims(object_mask, 4)\n",
    "        box_delta = box_mask*(predict_box_offset - true_box_offset)\n",
    "        box_loss = tf.reduce_mean(tf.reduce_sum(tf.square(box_delta), axis=[1,2,3]), name='box_loss')\n",
    "        \n",
    "        loss = 0.5*class_loss + object_loss + 0.1*noobject_loss + 10*box_loss\n",
    "        \n",
    "        return loss, iou_metric, predict_object, predict_class, predict_normalized_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R8MEe8sH9mWI"
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():    \n",
    "    images = tf.placeholder(\"float\", [None, img_size, img_size, 3], name=\"input\")\n",
    "    labels = tf.placeholder('float', [None, cell_size, cell_size, 8], name='label')\n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "    logits = vgg16(images, is_training)\n",
    "    loss, iou_metric, predict_object, predict_class, predict_normalized_box = loss_layer(logits, labels)\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "    train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ihiosiV-9mWL",
    "outputId": "9c7f2b92-db44-48ce-896e-b6818bd60b67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - running_time: 100s - train_loss: 0.608 - train_iou: 0.536 - val_loss: 0.651 - val_iou: 0.521\n",
      "epoch: 1 - running_time: 100s - train_loss: 0.269 - train_iou: 0.656 - val_loss: 0.287 - val_iou: 0.649\n",
      "epoch: 2 - running_time: 101s - train_loss: 0.205 - train_iou: 0.656 - val_loss: 0.212 - val_iou: 0.688\n",
      "epoch: 3 - running_time: 103s - train_loss: 0.155 - train_iou: 0.715 - val_loss: 0.174 - val_iou: 0.737\n",
      "epoch: 4 - running_time: 101s - train_loss: 0.140 - train_iou: 0.710 - val_loss: 0.164 - val_iou: 0.721\n",
      "epoch: 5 - running_time: 100s - train_loss: 0.120 - train_iou: 0.764 - val_loss: 0.139 - val_iou: 0.712\n",
      "epoch: 6 - running_time: 100s - train_loss: 0.109 - train_iou: 0.785 - val_loss: 0.128 - val_iou: 0.723\n",
      "epoch: 7 - running_time: 100s - train_loss: 0.107 - train_iou: 0.802 - val_loss: 0.131 - val_iou: 0.766\n",
      "epoch: 8 - running_time: 100s - train_loss: 0.099 - train_iou: 0.777 - val_loss: 0.116 - val_iou: 0.766\n",
      "epoch: 9 - running_time: 103s - train_loss: 0.086 - train_iou: 0.793 - val_loss: 0.110 - val_iou: 0.783\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    saver = tf.train.Saver(max_to_keep=1)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        for batch in range(len(X_train)//batch_size):\n",
    "            X_batch = X_train[batch*batch_size:(batch+1)*batch_size]\n",
    "            y_batch = y_train[batch*batch_size:(batch+1)*batch_size]\n",
    "            train_total_loss, train_iou_m,_ = sess.run([loss, iou_metric, train_op], {images:X_batch, labels:y_batch, is_training:True})            \n",
    "        end_time = time.time()\n",
    "        \n",
    "        val_loss = []\n",
    "        val_iou_ms = []\n",
    "        for batch in range(len(X_test)//batch_size):\n",
    "            val_X_batch = X_test[batch*batch_size:(batch+1)*batch_size]\n",
    "            val_y_batch = y_test[batch*batch_size:(batch+1)*batch_size]\n",
    "            total_val_loss, val_iou_m, val_predict_object, val_predict_class, val_predict_normalized_box = sess.run([loss, iou_metric, predict_object, predict_class, predict_normalized_box], \n",
    "                                                 {images:val_X_batch, labels:val_y_batch, is_training:False})\n",
    "            val_loss.append(total_val_loss)\n",
    "            val_iou_ms.append(val_iou_m)\n",
    "            \n",
    "        saver.save(sess, './model/yolo', global_step=epoch)\n",
    "        print('epoch: {} - running_time: {:.0f}s - train_loss: {:.3f} - train_iou: {:.3f} - val_loss: {:.3f} - val_iou: {:.3f}'.format(epoch, end_time - start_time, train_total_loss, train_iou_m, np.mean(val_loss), np.mean(val_iou_ms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DnEphdfj9mWO"
   },
   "outputs": [],
   "source": [
    "def iou(box1, box2):\n",
    "    \n",
    "    tb = min(box1[0] + 0.5 * box1[2], box2[0] + 0.5 * box2[2]) - \\\n",
    "        max(box1[0] - 0.5 * box1[2], box2[0] - 0.5 * box2[2])\n",
    "    lr = min(box1[1] + 0.5 * box1[3], box2[1] + 0.5 * box2[3]) - \\\n",
    "        max(box1[1] - 0.5 * box1[3], box2[1] - 0.5 * box2[3])\n",
    "    inter = 0 if tb < 0 or lr < 0 else tb * lr\n",
    "    return inter / (box1[2] * box1[3] + box2[2] * box2[3] - inter)\n",
    "    \n",
    "def interpret_output(predict_object, predict_class, predict_normalized_box):\n",
    "    predict_box= predict_normalized_box*img_size\n",
    "    predict_object = np.expand_dims(predict_object, axis=-1)\n",
    "    predict_class = np.expand_dims(predict_class, axis=-2)\n",
    "    class_probs = predict_object*predict_class\n",
    "    \n",
    "    filter_mat_probs = np.array(class_probs >= 0.2, dtype='bool')\n",
    "    filter_mat_boxes = np.nonzero(filter_mat_probs)\n",
    "    boxes_filtered = predict_box[filter_mat_boxes[0], filter_mat_boxes[1], filter_mat_boxes[2]]\n",
    "    class_probs_filtered = class_probs[filter_mat_probs]\n",
    "    \n",
    "    classes_num_filtered = np.argmax(\n",
    "        filter_mat_probs, axis=3)[\n",
    "        filter_mat_boxes[0], filter_mat_boxes[1], filter_mat_boxes[2]]\n",
    "\n",
    "    argsort = np.array(np.argsort(class_probs_filtered))[::-1]\n",
    "    boxes_filtered = boxes_filtered[argsort]\n",
    "    class_probs_filtered = class_probs_filtered[argsort]\n",
    "    classes_num_filtered = classes_num_filtered[argsort]\n",
    "\n",
    "    for i in range(len(boxes_filtered)):\n",
    "        if class_probs_filtered[i] == 0:\n",
    "            continue\n",
    "        for j in range(i + 1, len(boxes_filtered)):\n",
    "            if iou(boxes_filtered[i], boxes_filtered[j]) > 0.5:\n",
    "                class_probs_filtered[j] = 0.0\n",
    "                \n",
    "    filter_iou = np.array(class_probs_filtered > 0.0, dtype='bool')\n",
    "    boxes_filtered = boxes_filtered[filter_iou]\n",
    "    class_probs_filtered = class_probs_filtered[filter_iou]\n",
    "    classes_num_filtered = classes_num_filtered[filter_iou]\n",
    "\n",
    "    result = []\n",
    "    for i in range(len(boxes_filtered)):\n",
    "        result.append(\n",
    "            [classes_num_filtered[i],\n",
    "             boxes_filtered[i][0],\n",
    "             boxes_filtered[i][1],\n",
    "             boxes_filtered[i][2],\n",
    "             boxes_filtered[i][3],\n",
    "             class_probs_filtered[i]])\n",
    "\n",
    "    return result\n",
    "\n",
    "def draw_result(img, result):\n",
    "    \n",
    "    plt.figure(figsize=(10,10), dpi=40)\n",
    "    img = np.pad(img, [(50,50), (50,50), (0,0)], mode='constant', constant_values=255)\n",
    "    for i in range(len(result)):\n",
    "        x = int(result[i][1])+50\n",
    "        y = int(result[i][2])+50\n",
    "        w = int(result[i][3] / 2)\n",
    "        h = int(result[i][4] / 2)\n",
    "        cv2.rectangle(img, (x - w, y - h), (x + w, y + h), (231, 76, 60), 2)\n",
    "        cv2.rectangle(img, (x - w, y - h - 20),\n",
    "                      (x -w + 50, y - h), (46, 204, 113), -1)\n",
    "        cv2.putText(\n",
    "            img, '{} : {:.2f}'.format(result[i][0] ,result[i][5]),\n",
    "            (x - w + 5, y - h - 7), cv2.FONT_HERSHEY_SIMPLEX, 0.3,\n",
    "            (0, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h2ynBhLo9mWR"
   },
   "outputs": [],
   "source": [
    "img_idx = 15\n",
    "result = interpret_output(val_predict_object[img_idx], val_predict_class[img_idx], val_predict_normalized_box[img_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Y2NlwHC9mWU"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_result(val_X_batch[img_idx]*255, result)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1rjC-BEK9mWa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "solution-yolo.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
